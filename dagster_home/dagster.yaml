# Dagster instance configuration

# Storage configuration - using PostgreSQL
storage:
  postgres:
    postgres_db:
      username:
        env: DAGSTER_POSTGRES_USER
      password:
        env: DAGSTER_POSTGRES_PASSWORD
      hostname:
        env: DAGSTER_POSTGRES_HOST
      db_name:
        env: DAGSTER_POSTGRES_DB
      port:
        env: DAGSTER_POSTGRES_PORT

# Run launcher configuration
run_launcher:
  module: dagster.core.launcher
  class: DefaultRunLauncher

# Run coordinator configuration
run_coordinator:
  module: dagster.core.run_coordinator
  class: QueuedRunCoordinator

# Code server configuration
code_servers:
  local_startup_timeout: 180

# Telemetry settings (optional - disable if desired)
telemetry:
  enabled: false

# Retention policy for old runs (optional)
retention:
  schedule:
    purge_after_days: 90
  sensor:
    purge_after_days: 90

# Sensor configuration
sensors:
  use_threads: true
  num_workers: 4

# Python logging
python_logs:
  managed_python_loggers:
    - "" # Capture the root logger (recommended)
    - config.logging # Capture your custom logging setup module

  # Set the default log level for captured Python loggers
  python_log_level: INFO

  # Add handlers and formatters â€” these will be attached by Dagster
  # They *supplement* your existing handlers from logging.py
  dagster_handler_config:
    handlers:
      console:
        class: logging.StreamHandler
        level: INFO
        formatter: dagster
        stream: ext://sys.stdout

      file_handler:
        class: logging.handlers.RotatingFileHandler
        filename: /opt/dagster/dagster_home/monitoring/logs/dagster_combined.log
        maxBytes: 10485760 # 10 MB per file
        backupCount: 5
        level: INFO
        formatter: dagster

    formatters:
      dagster:
        format: "%(asctime)s - [%(levelname)-8s] - %(name)-30s - [%(funcName)s:%(lineno)d] - %(message)s"
        datefmt: "%Y-%m-%d %H:%M:%S"
